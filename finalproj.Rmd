--- 
title: "Housing Price Analysis"
author: "Felix Yeung / Yingfei Zhu / Yufan Cao"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```

# Introduction

The purpose of this study is to better understand the shift in Real Estate Prices across the 50 U.S. States and its relationship with key economic variables. This study will work towards uncovering the insights & relationships between unemployment, income, population, and housing units to determine if/how these variables drive home prices across the country. 

The team chose to investigate this topic because affordable housing is one of the most important human needs. In addition to the basic need of shelter, affordable housing provides opportunities for schooling, for work, for economic activities, and for better urban planning. Residents can gain access to better schooling systems and work opportunities. Businesses can better flourish within communities with higher purchasing power. Communities can become more diverse and vibrant. 

Furthermore, home purchase is one of the biggest financial decisions that a family can make. Itâ€™s an asset purchase that typically sticks with the buyer between 15-30 years. Most buyers spend between 25-40% of net worth on real estate purchases. 

Given the importance of home values to our everyday lives, we want to use the data to better understand the economic trends of society and the real estate market by answering but not limited to the following key questions: 

How has home values changed over time across 50 States?
Is there a relationship between home value and income/unemployment?
Is there a relationship between home value and population change?
Etc.

<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Data sources

## Home Value Data
Our goal is to explore how U.S. real estate prices in different states/cities change over the years and how economic variables effect these prices. As such, we obtained our primary dataset, which contain home value information, from Zillow's housing data division (https://www.zillow.com/research/data/). 

Although there are many well-known real estate websites that can provide similar data, such as foreclosure and realtor, we ultimately chose the data from Zillow as our home value resource. Zillow is the premier real estate website in the US. Not only does  Zillow provide services to customers for selling, buying, renting and financing in real estate industry, the company also has a research division that focuses on collecting the most up-to-date real estate information in the US market. Their research includes home value, inventory, sale price, etc. We trust Zillow's database because the company is open about data sources and respects the integrity of data. (https://www.zillow.com/research/about-us/) Furthermore, the Zillow Research team states that the purpose of their research is not aimed at business profit and the team also made the code open sourced to ensure the accuracy in their home value data. The research team collects their data using their Econ Data API which can be reached from the Postman website. (https://documenter.getpostman.com/view/9197254/SzRuZCCj?version=latest)

We obtained the original data set about home value in a monthly and city level base. The raw data set contains 5 categorical variables to describe the region and name of city or state. It also has the information about size rank and region type. Home value are described through Zillow Home Value Index (ZHVI, the home value measurement in different regions within the US. The detail of the methodology of Zillow Home Value Index can be found in the Zillow Research methodology introduction website. (https://www.zillow.com/research/zhvi-methodology-2019-deep-26226/) We have monthly home value for each city from 01/31/00 to 10/31/21 (in total 250 months). 

The potential problems of this dataset can be divided into two aspects. First, we have a significant amount of missing data for the Zillow Home Value Index, especially for early years around 2010. Second, the dataset was too granular and drilled down to the city level for each month within the past ten years. If we continue to focus on city and monthly level data, it could conceal the trend of the data could make the graph hard by cluttering the analysis.

## Other Variables

Before we officially start the exploratory data analysis, we discussed the key economic variables that could potentially influence home value. After brainstorming and research, we decided to focus on the most interesting variables: population, hosing unit, income and unemployment rate in the corresponding states.
We obtained the above mentioned data for each state from 2010 to 2019 using the  Census Bureau official website (https://www.census.gov). To be more specific, each resource and related methodology are listed below:

### Population

Source: https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html  
Methodology https://www2.census.gov/programs-surveys/popest/technical-documentation/methodology/2010-2019/natstcopr-methv2.pdf.

### Housing unit

Source: https://www2.census.gov/programs-surveys/popest/tables/2010-2019/housing/totals/NST-EST2019-ANNHU.xlsx  
Methodology: https://www2.census.gov/programs-surveys/popest/technical-documentation/methodology/2010-2019/2019-hu-meth.pdf

### Income
Source: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiBueaZ0tH0AhWKmHIEHZ-WBasQFnoECBYQAQ&url=https%3A%2F%2Fwww2.census.gov%2Fprograms-surveys%2Fcps%2Ftables%2Ftime-series%2Fhistorical-income-households%2Fh08.xls&usg=AOvVaw0MqyTNSJP8VVd2wWKeoHeo

### Unemployment Rate
Additionally, we also used the unemployment rate 2010-2018 gathered by Local Area Unemployment Statistics, U.S. Bureau of Labor Statistics (BLS) and stored in the Iowa state university community indicators program dataset
Source: https://www.icip.iastate.edu/tables/employment/unemployment-states
We added the 2019 unemployment rate using the record of BLS official website: https://www.bls.gov/lau/lastrk19.htm


<!--chapter:end:02-data.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Data transformation

```{r echo=FALSE,message=FALSE}
library(tidyverse)
library(plyr)
library(dplyr)
homevalue_city <- read.csv(file = 'data/homevalue_city_clean.csv')
```


```{r echo=FALSE}
homevalue2010 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2010),list(X2010 = mean))
homevalue2011 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2011),list(X2011 = mean))
homevalue <- cbind(homevalue2010, X2011=homevalue2011$X2011)

homevalue2012 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2012),list(X2012 = mean))
homevalue <- cbind(homevalue, X2012=homevalue2012$X2012)

homevalue2013 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2013),list(X2013 = mean))
homevalue <- cbind(homevalue, X2013=homevalue2013$X2013)

homevalue2014 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2014),list(X2014 = mean))
homevalue <- cbind(homevalue, X2014=homevalue2014$X2014)

homevalue2015 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2015),list(X2015 = mean))
homevalue <- cbind(homevalue, X2015=homevalue2015$X2015)

homevalue2016 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2016),list(X2016 = mean))
homevalue <- cbind(homevalue, X2016=homevalue2016$X2016)

homevalue2017 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2017),list(X2017 = mean))
homevalue <- cbind(homevalue, X2017=homevalue2017$X2017)

homevalue2018 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2018),list(X2018 = mean))
homevalue <- cbind(homevalue, X2017=homevalue2017$X2017)

homevalue2019 <- homevalue_city %>% group_by(homevalue_city$StateName) %>% 
  summarise_at(vars(X2019),list(X2019 = mean))
homevalue <- cbind(homevalue, X2019=homevalue2019$X2019)

write.csv(homevalue,"home_value_state.csv", row.names = TRUE)

```

Since we have a large amount of data from multiple sources, we decided to clen the data (details about methodology can be found in Chapter 4: Missing value) and build two data sets for our visualization. 

The first one is the data set that contain the yearly average home value data for each state. To summaries the home value of each city into each state, we calculated the home value in a certain year by averaging the home value of all the cities in that state. Similarly, to summarize our monthly data to yearly data, we averaged home value across the 12 months in a year and stored it as the yearly home value. The result is a home value data set for each state from 2010-2019 that includes state name, state initial and home value for 10 years.

The second dataset we generated is the mixed data set for all our economic variables that may have an effect on home value as we listed before. Since we have 5 variables (state, home value, income, unemployment, and population), we collected 10 years worth of data and then transformed it from 3D to 2D. We used pivot-longer to increase the number of rows by transforming 'Year' as a column to keep in line with tidy principles. 

Finally with these 2 data sets, we decided to further combine them so that each row of the data set would contain the following 8 variables: Area (state full name), State Name (state initial), Year, Home value, Population, Housing Unit, Unemployment rate, and Income. This final dataset would contain informatiom from all 50 States across the years 2010 to 2019.



<!--chapter:end:03-cleaning.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Missing values

```{r, echo = FALSE, warning = FALSE, message=FALSE}

rawdata <- read.csv("homevalue_city_missing.csv")

rawdata<- as.data.frame(sapply(rawdata, as.numeric))
rawdata <- subset(rawdata, select = -c(1,2))
```

```{r, echo = FALSE, warning = FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
plot_missing <- function(x, percent = TRUE) {	
  na_count_all <- data.frame(is.na(x)) %>%	
    group_by_all() %>%	
    count(name = "count", sort = TRUE) %>%	
    ungroup() %>%	
    rownames_to_column("pattern")	
  
  na_count_all <- na_count_all %>% 
    mutate(pattern = factor(pattern, levels = nrow(na_count_all):1))
  
  # count the number of columns with missing values; will be used later to determine if there's a "none missing" pattern	
  na_count_all <- na_count_all %>% 	
    rowwise() %>%	
    mutate(num_missing_cols = sum(c_across(where(is.logical))))	
  
  # data frame for missing patterns bar chart	
  na_count_by_pattern <- na_count_all %>% 	
    select(pattern, count, num_missing_cols) %>% 	
    mutate(none_missing = ifelse(num_missing_cols == 0, TRUE, FALSE))
  
  # data frame for missing by column bar chart	
  na_count_by_column <- data.frame(is.na(x)) %>%	
    colSums() %>% 	
    sort(decreasing = TRUE) %>% 	
    enframe(name = "var", value = "count")	
  
  # tidy and sort na_count_all by column counts	
  na_count_all_tidy <- na_count_all %>% 	
    pivot_longer(where(is.logical), names_to = "variable") %>%	
    mutate(variable = factor(variable, levels = na_count_by_column$var))  %>% 	
    mutate(none_missing = ifelse(num_missing_cols == 0, TRUE, FALSE))	
  
  # main plot
  main_plot <- ggplot(na_count_all_tidy, aes(variable, pattern, fill = factor(value), alpha = none_missing)) +	
    geom_tile(color = "white") +	
    scale_fill_manual(values = c("grey70", "mediumpurple")) +	
    scale_alpha_manual(values = c(.7, 1)) +	
    ylab("missing pattern") +	
    guides(fill = "none", alpha = "none") +	
    theme_classic(12)	
  
  # check for "none missing" pattern
  none_missing_pattern <- na_count_by_pattern %>%
    filter(none_missing) %>% pull(pattern)
  
  if (length(none_missing_pattern) > 0) {	
    main_plot <- main_plot +	
      annotate("text", x = (ncol(na_count_all)-2)/2,	
               y = nrow(na_count_all) + 1 - as.numeric(as.character(none_missing_pattern)),	
               label = "complete cases")	
  }	
  
  # margin plots
  
  denom <- ifelse(percent, nrow(x)/100, 1)
  
  missing_by_column_plot <- ggplot(na_count_by_column, aes(fct_inorder(var), count/denom)) +	
    geom_col(fill = "cornflowerblue", alpha = .7) + xlab("") +	
    scale_y_continuous(expand = c(0, 0), n.breaks = 3) +	
    ylab(ifelse(percent, "% rows \n missing:", "num rows \n missing:")) +	
    theme_linedraw(12) + 	
    theme(panel.grid.major.x = element_blank(),	
          panel.grid.minor.x = element_blank())	
  
  missing_by_pattern_plot <- 
    ggplot(na_count_by_pattern, aes(pattern, count/denom, alpha = none_missing)) +
    geom_col(fill = "cornflowerblue") +
    coord_flip() +
    scale_y_continuous(expand = c(0, 0), n.breaks = 3) +
    scale_alpha_manual(values = c(.7, 1)) +
    xlab("") +
    ylab(ifelse(percent, "% rows", "row count")) +
    guides(alpha = "none") +
    theme_linedraw(12) +
    theme(panel.grid.major.y = element_blank(), 
          panel.grid.minor.y = element_blank())
  
  if (percent) {	
    missing_by_column_plot <- missing_by_column_plot +
      scale_y_continuous(expand = c(0, 0), n.breaks = 5,
                         limits = c(0, 100))	
    missing_by_pattern_plot <- missing_by_pattern_plot +
      scale_y_continuous(expand = c(0, 0), n.breaks = 5,
                         limits = c(0, 100))	
  }	
  
  missing_by_column_plot + plot_spacer() + 	
    main_plot + missing_by_pattern_plot + 	
    plot_layout(widths = c(4, 1), heights = c(1, 4))
}

```

```{r, echo = FALSE, warning = FALSE, message=FALSE}
plot_missing(rawdata, percent = FALSE)
```


As mentioned in our data source section, the datasets we are using for this investigation comes from Census and Zillow. The Census datasets that we are referencing contains information such as income, population, unemployment, and housing unit. These datssets come from the government organization and are mostly complete. However, on the other hand, the home value data from Zillow, which contains 10 years of price data across 900 distinct cities in US, are missing many data points. By plotting the Zillow Data using the missing value plot, we notice that year 2010 has the maximum number of missing values of 'homevalue', and the number of missing values decreases gradually over the years. 


To supplement these missing values, we perform an imputation for our missing value Since our data is time series of home value from year 2010 to year 2019, we applied the Time-series Specific method. The time series method of imputation assume the adjacent observations will be similar to the missing data. These assumpetions work well for price over time as each data point would be similar to its temporal neighbors.


<!--chapter:end:04-missing.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Results


```{r, echo=FALSE, results='hide', message=FALSE}
#Load Clean Data
df <- read.csv("fulldata_state.csv")
```

```{r, echo=FALSE, results='hide', message=FALSE}
library(corrplot)
library(GGally)
library(ggplot2)
library(ggrepel)
library(geofacet)
library(ggpubr)
library(dplyr)
library(usmap) #import the package
library(choroplethr)
library(statebins)
library(hrbrthemes)
library(systemfonts)
library(viridis)
library(forcats)
```




## Understanding relationships between economic variables


In the first step of the investigation, its important to uncover relationships between each of the variables to determine the most interesting direction for the team to cover. The most obvious way is to determine whether there's any correlations exist between home value, population, housing unit, unemployment, and income. This can be achieve through a correlation matrix, pairs plot, parallel coordinates chart. 

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
housedata <- df
numframe <- housedata[,4:8]

M <- cor(numframe)

corrplot(M, method="number")

pairs(numframe)

```

  In the correlation matrix above, it is most obvious that there is a strong correlation between population and housing unit over the years. This should be natural in normal functioning society with low number of homelessness. However, there doesn't seem to be any correlation between population and housing unit, which is interesting because this suggests that increasing population did not put upward pressure towards home values. Again, this can indiate that the home building market is efficient and is keeping up with population thus relieving any potential pent up demand. 

  The second interesting observation here is the correlation (0.62) between income and home value. This suggests that increase in income in a State is also linked to increasing home values. Delving deeper, unemployment rate is negatively correlated (-0.52) to income but has little to no correlation (-0.18) to home values. This is interesting because perhaps income is a bridging variable that connect unemployment to home values.

These results confirm this by viewing in a different perspective via parallel coordinates chart.


```{r, fig.width=20, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}

ggparcoord(housedata, columns = 4:8, alphaLines = .3,scale = "uniminmax") + 
  facet_wrap("Year") + 
  theme(axis.text.x=element_text(angle=45, hjust=1), axis.text=element_text(size = 7),axis.title.x = element_text(size = 7)) + 
  labs(title = "Paralellel Coordinates of Key Economic Variables", subtitle = '2010 - 2019')

```


By graphing the parallel coordinates plot and faceting over the years, the results confirm the relationships between unemployment rate, income, and home value. Furthermore, it provides insights into how it changes over time. The results suggest that following the 2008 recession unemployment rate steadily declined which lead to a increase income and then lead to an increase in home value in some states. It also confirms that population and housing unit are coorelated with each other but have no correlations with other variables.

## Visualizing the known relationships

After discovering the relationships between unemployment rate, income, and home value, we can extrapolate further by visualizing relationships between these variables in different perspectives. 

```{r, fig.height=15, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7, warning = FALSE}

p <- ggplot(housedata, aes(x=housedata$Unemployment.Rate, y=housedata$Income)) + geom_point() + facet_wrap(housedata$Year) + geom_density_2d() +
  xlab("Unemployment Rate") + ylab("Income ($)") + labs(title = "Density Distribution of Income vs Unemployment Rate", subtitle = '2010 - 2019') 

ggplot(housedata, aes(x=housedata$Income, y=housedata$Home.Value)) + geom_point() + facet_wrap(housedata$Year) + geom_density_2d() +
  xlab("Income ($)") + ylab("Home Value ($)") + labs(title = "Density Distribution of Home Value vs Income", subtitle = '2010 - 2019') + 
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::comma)

```


Reviewing the distribution between those 3 variables, the economic trends becomes much more apparent. First, focusing on unemployment rates vs income, following the financial crisis in 2010, unemployment rate across U.S. has a huge variance between 4% to 13%. During this year and the subsequent years, wages were capped between $40k to $80k. It wasn't until unemployment rate was under control and below 7.5% that wages collectively increased. 

Now that we understand unemployment rate is a prerequisite for rising income, we can focus on income vs home values. Throughout the years, it can be observed that rising income leads to more expensive home prices. In fact, a wider range in income actually leads to a wider distribution of home value prices. In the beginning of the decade when income was much less distributed, home values across states also had less variance and was clustered under $200k per home. However, towards the end of the decade in 2019, home values & and income became significantly more distributed.


## Observing key variables across geographies

Now that these relationships are better understood, let's explore how these trends shift and compare across different geographies.

We will first look at unemployment rate over the past decade. 

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=9,fig.height=9}
unemployment <- subset(df, select = -c(1,4,5,6,8))
colnames(unemployment) <- c('state','year','unemployment')

plot_usmap(data = unemployment, values = "unemployment", color = "white") +
  facet_wrap(~year) +
   scale_fill_continuous(low = "skyblue", high = "yellow", name = "Unemployment") +
  labs(title = "Unemployment by States", subtitle = 'Yearly Adjusted') +
  theme(legend.position = "right")
```

From our observations of the choropleth heat map over time, West & South East had the most severe unemployment rate in 2010. The recovery in the 9 years since then is significant. States like Nevada and California bridged 5-7% differences. It is notable because California had one of the highest unemployment rates but now commands some of the highest home prices in the U.S.

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=8,fig.height=8}
uny2010 <- unemployment[unemployment$year == '2010',]

p2 <- plot_usmap(data = uny2010, values = "unemployment", color = "white") +
   scale_fill_continuous(low = "light blue", high = "dark blue", name = "Unemployment") +
  labs(title = "State Unemployment Rates", subtitle = 'Year 2010') +
  theme(legend.position = "none") 
```

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=9,fig.height=9}
p1 <- ggplot(uny2010) +
geom_bar(aes(fct_reorder(state, -unemployment), unemployment, fill=unemployment), alpha = .8, stat="identity", width = 0.8) +
scale_fill_gradient("Percentage", low = "light blue", high = "dark blue") +
labs(x=" ", y=" ") +
  scale_y_continuous(limits = c(0, 14), breaks = seq(0, 14, 2)) +
  theme_bw() +
   theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank()) +
  theme(legend.position = "none") +
  theme(axis.text=element_text(size=6))

```


```{r, echo=FALSE, results='hide', message=FALSE, fig.width=9,fig.height=9}

SoilSciGuylabs <- c("Citrus", "Crop", "Cypress Swamp")
p3 <- ggplot(uny2010) + 
  geom_histogram(aes(x = unemployment,y = after_stat(count), fill = ..x..), bins = 5, binwidth = 2) +
  scale_fill_gradient2( low = "light blue", high = "dark blue") +
  scale_x_continuous(limits = c(3, 13), breaks = seq(4, 14, 2)) +
  theme(panel.background = element_blank()) +
  theme(axis.title.x  =element_blank(),
        axis.text.x =element_blank(),
        axis.ticks.y =element_blank(),
        axis.ticks.x =element_blank()) +
  theme(legend.position = "none") +
  coord_flip() +
  labs(x=" ", y=" ")
  

```


```{r, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
library(patchwork)

patch = (p2 | p3) +  plot_layout(widths = c(4, 1))
final_plot <- p1 / patch +  plot_layout(widths = c(5, 1), heights = c(1, 4))
final_plot
```



Taking a closer look in the unemployment landscape of 2010, the results are remarkable given the current state of employment rates & home values. Notable states that had the highest unemployment rates amongst States are Nevada, Michigan, California, and Florida. As we review Income & Home Value, it will be more apparent that these States are notable because of their dramatic recovery. 

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
# choropleth by income
income <- subset(df, select = -c(1,4,5,6,7))

colnames(income) <- c('state','year','income')

plot_usmap(data =income, values = "income", color = "white") +
  facet_wrap(~year) +
   scale_fill_continuous(low = "mediumspringgreen", high = "red", name = "Income", labels = scales::comma) +
  labs(title = "Income by States", subtitle = 'Yearly adjust') +
  theme(legend.position = "right")

```

As unemployment rate improved, the states that had the worst unemployment rates actually turned to have the highest incomes or neighbor states that have the highest income.

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
homevalue <- subset(df, select = -c(1,5,6,7,8))
colnames(homevalue) <- c('state','year','homevalue')

plot_usmap(data = homevalue, values = "homevalue", color = "white", labels = FALSE) +
  facet_wrap(~year) +
   scale_fill_continuous(low = 'skyblue', high = 'red', name = "Homevalue", labels = scales::comma) +
  labs(title = "Home Value by States", subtitle = 'Yealy Adjusted') +
  theme(legend.position = "right")
```

Noted form before, home values typically follow income. The states that developed the highest income also developed comparatively higher home prices. However, looking at the map, there's another notable trend that can be observed. Despite having some of the highest income in US, the home prices in the Northeastern part of the country did not rise as dramatically as the Western part of the US. There's not enough data to conclusively understand why; perhaps we can augment the analysis in the future with weather data, sentiments, etc. to better understand. 

```{r, fig.height=15, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
ggplot(housedata, aes(x=housedata$Income, y=housedata$Home.Value, color=housedata$State.Name)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  facet_geo(~ State.Name, grid = "us_state_grid2") +
  stat_cor(aes(label = ..rr.label..), color = "red", geom = "label", size = 2)  + 
  theme(legend.position = "none") +
  xlab("Income ($)") + 
  ylab("Home Value ($)") + 
   scale_y_continuous(labels = scales::comma) + 
   scale_x_continuous(labels = scales::comma) + 
  labs(title = "Home Value vs Income", subtitle = '2010 - 2019 across 50 States') 
```


Lastly, by graphic Income vs Home Value for each of the State, we can validate our findings with a trend a line and Rsquared values. We can confirm that the notable Western States (e.g. CA & NV) have a steeper slope when compared to the rest of the States; this supports our theory that it has the fastest growth in income and home value prices over the last decade. 

We can also confirm that select Northeastern States have an increase in income but home value has not grown comparatively (e.g. NJ & CT)


## Price comparison of Home Value

Finally, to conclude this study, we will further investigate home value to better understand the specifics of how it changes for each State over the years. Through understanding the price dynamics across the market, we can perhaps help buyers/readers understand the history and navigate purchasing decisions. 


```{r, fig.height=10, echo=FALSE, results='hide', message=FALSE, fig.width=6.5,fig.height=6.5}

ggplot(housedata, aes(x = housedata$Home.Value, y = reorder(housedata$State.Name, housedata$Home.Value), color =df$Year)) +
  geom_point() +
  ylab("") +
  theme_linedraw() +
  theme(legend.position = "right") +
  xlab("Home Value ($)") + ylab("State") + labs(title = "Home Value over the years", subtitle = '2010 - 2019') + scale_color_gradientn(name = 'Year', colours = topo.colors(7), breaks=c(2010, 2015, 2019))
         
```


From the above Cleveland Dot Plot, it is apparent that the most expensive States continued to be the most expensive. The markets that are hottest actually had the biggest price increases from the past decade and increased prices in multiples while cheaper markets only have modest gains (e.g. HI, CA, etc.) 

It is notable that most States have the highest value in the most recent year of 2019 with a few exceptions: Rhode Island & New Jersey.

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
fulldata <- read.csv("fulldata_state.csv")

northeast <- c('ME','NH','VT','MA','RI','CT','NY','NJ','PA')
midwest <- c('ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH')
south <- c('OK','TX','AR','LA','MS','AL','TN','KY','WV','VA','NC','SC','GA','FL','DE','MD','DC')
west <-  c('WA','OR','CA','MT','ID','NV','UT','AZ','WY','CO','NM','AK','HI')
fulldata$region <- as.factor(ifelse(fulldata$State.Name %in% northeast, 'Northeast',
                     ifelse(fulldata$State.Name %in% midwest, 'Midwest', 
                     ifelse(fulldata$State.Name %in% south, 'South',
                            ifelse(fulldata$State.Name %in% west, 'West','null')))))
```

```{r, fig.width=20, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
ggplot(fulldata, aes(region,Home.Value)) + 
  geom_boxplot() + 
  facet_wrap("Year") +
  scale_y_continuous(labels = scales::comma) +
  coord_flip() +
  theme_grey(16)
```


Next, we can divide the geography into the 4 major regions in US. Looking at the distributions, here are the main insights:

1. The order of descending median home values are as follows: West, NorthEast, South, and MidWest. 
2. West has the most amount outliers on the bottom range and top range. 
3. Although South has a lower median than Northeast, the most expensive outliers are more expensive than most of Northeast.
4. Northeast distribution of prices have remained relatively stable throughout the decade. 
5. Midwest has the cheapest real estate and also the most narrow distribution

```{r, echo=FALSE, results='hide', message=FALSE, fig.width=7,fig.height=7}
df <- transform(df, ValuePerIncome = df$Home.Value /df$Income)
target <- c(2010, 2019)
subdf <- filter(df, Year %in% target)

print(subdf)

ggplot(subdf, aes(x = subdf$ValuePerIncome, y = reorder(subdf$State.Name, subdf$ValuePerIncome), color = as.factor(subdf$Year))) +
  geom_point() +
  ylab("") +
  theme_linedraw() +
  theme(legend.position = "right") + scale_color_manual(name = "Year", values = c("red", "blue")) +
  xlab("Price/Income") + ylab("State") + labs(title = "Home Value / Income Ratio across 50 States", subtitle = '2010 - 2019')
```

```{r, fig.height=15, echo=FALSE, results='hide', message=FALSE, fig.width=8,fig.height=8, warning = FALSE}

ggplot(subdf, aes(x=subdf$Year, y=subdf$ValuePerIncome, color=subdf$State.Name)) + geom_point() + geom_smooth(method = "lm") + facet_geo(~ State.Name, grid = "us_state_grid2") +
  stat_cor(aes(label = ..rr.label..), color = "red", geom = "label")  + theme(legend.position = "none") +
  xlab("Price/Income") + ylab("Year") + labs(title = "Home Value / Income Ratio across 50 States", subtitle = '2010 - 2019')
```


As a final statement in this study, we also want to learn whether the growth in income have kept pace with the growth in home value. After all, if income was not able to keep pace, then the rise in home value could actually be a detriment to communities because it makes the housing less affordable. We do this by charting Value/Income.

For the most part, states have maintained or improved on this ratio; we can observe this by the flat to downward slope. This is especially apparent in the Northeastern part of U.S. 

On the other hand, the Western Part of the US which have seen significant increase in Home Value have actually deteriorated this ratio; we can observe this by the positive slope. This is especially apparent for States such as CA, NV, CO, etc.

<!--chapter:end:05-results.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Interactive component

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ion-rangeslider/2.3.1/css/ion.rangeSlider.min.css"/>
<style>
        body {
            overflow: hidden;
        }

        .page {
            display: none;
        }

        .chart {
            width: 960px;
            padding: 10px;
            border: 1px solid #ccc;
            margin: 0 auto;
        }

        .tooltip {
            position: absolute;
            content: attr(data-tooltip);
            text-align: left;
            min-width: 3em;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            padding: 15px 8px;
            border-radius: 3px;
            background: #F3F3F6;
            opacity: 0.6;
            color: #000000;
            z-index: 9999;
            -moz-box-shadow: 3px 3px 5px #888888;
            /* Firefox */
            box-shadow: 3px 3px 5px #888888;
        }

        .range-slider-box {
            width: 90%;
            margin: 0 auto;
        }

        .title {
            text-align: center;
            margin: 10px;
        }

        .remark {
            position: absolute;
            margin-left: 10px;
            margin-top: -40px;
            font-size: 13px;
            text-align: left;
            padding: 10px 10px;
            padding-top: 0;
            padding-bottom: 0;
            color: rgb(119, 119, 119);
        }
</style>
    
<div class="page">
<div id="map-chart" class="chart">
<h2 class="title">Home Value by States (Year 2010-2019)</h2>
<div class="range-slider-box">
<input type="text" id="range-slider" name="my_range" value="" />
</div>
<svg></svg>
<div class="remark">
<div>Hover over a state to see data</div>
<div>Hover over lengend items to see states in a category</div>
</div>
</div>
</div>
<script src="https://code.jquery.com/jquery-3.2.0.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/ion-rangeslider/2.3.1/js/ion.rangeSlider.min.js"></script>
<script src="https://d3js.org/d3.v7.min.js" charset="utf-8"></script>
<script src="https://unpkg.com/topojson@3.0.2/dist/topojson.min.js"></script>

<script>
        var aWidth = 900;
        var aHeight = 500;
        var currentYear = "2019";
        var dataMap = {};
        var aData = null;
        var mapRoot = null;
        var max = 700000;
        var sectionValues = [
            0,
            100000,
            200000,
            300000,
            400000,
            500000,
            600000,
            700000
        ];
        var hoverColor = "#e7e717";

        // define info box
        var tooltip = d3.select("body")
            .append("div")
            .attr("class", "tooltip")
            .style("opacity", 0.0);


        // create content for info box based on data
        function tooltipContent(list, title) {
            var tpl = "<div style='margin-top:5px;'><span>";
            tpl += "{name}: </span>{value}</div>";
            var html = "<div style='padding-left:20px;padding-right: 20px;padding-bottom:10px;font-size:12px;'>";
            if (title) {
                html += "<h4>" + title + "</h4>";
            }
            list.forEach(function (dataItem) {
                name = dataItem.name, value = dataItem.value;
                html += tpl.replace("{name}", name).replace("{value}", value);
            });
            html += "</div>";
            return html;
        }

        function getValue(realVal) {
            for (let index = 0; index < sectionValues.length; index++) {
                if (realVal < sectionValues[index]) {
                    return sectionValues[index];
                }
            }
            return 0;
        }

        var startColor = d3.rgb(202, 211, 237);
        var endColor = d3.rgb(45, 80, 157);
        var computeColor = d3.interpolate(startColor, endColor);
        var colorLinear = d3.scaleLinear()
            .domain([0, max])
            .range([0, 1])
            ;
        var color = function (value) {
            return computeColor(colorLinear(getValue(value)));
        };

        function MapChart(opt) {
            var width = opt.width;
            var height = opt.height;
            var map = opt.map;
            var max = opt.max;
            var data = opt.data;

            var colorScale = d3.scaleOrdinal([
                "#7D74FE", "#7DFF26", "#F84F1B", "#28D8D5", "#FB95B6", "#9D9931", "#F12ABF", "#27EA88", "#549AD5", "#FEA526",
                "#7B8D8B", "#BB755F", "#432E16", "#D75CFB", "#44E337", "#51EBE3", "#ED3D24", "#4069AE", "#E1CC72", "#E33E88",
                "#D8A3B3", "#428B50", "#66F3A3", "#E28A2A", "#B2594D", "#609297", "#E8F03F", "#3D2241", "#954EB3", "#6A771C",
                "#58AE2E", "#75C5E9", "#BBEB85", "#A7DAB9", "#6578E6", "#932C5F", "#865A26", "#CC78B9", "#2E5A52", "#8C9D79",
                "#9F6270", "#6D3377", "#551927", "#DE8D5A", "#E3DEA8", "#C3C9DB", "#3A5870", "#CD3B4F", "#E476E3", "#DCAB94",
                "#33386D", "#4DA284", "#817AA5", "#8D8384", "#624F49", "#8E211F", "#9E785B", "#355C22", "#D4ADDE", "#A98229",
                "#E88B87", "#28282D", "#253719", "#BD89E1", "#EB33D8", "#6D311F", "#DF45AA", "#E86723", "#6CE5BC", "#765175",
                "#942C42", "#986CEB", "#8CC488", "#8395E3", "#D96F98", "#9E2F83", "#CFCBB8", "#4AB9B7", "#E7AC2C", "#E96D59",
                "#929752", "#5E54A9", "#CCBA3F", "#BD3CB8", "#408A2C", "#8AE32E", "#5E5621", "#ADD837", "#BE3221", "#8DA12E",
                "#3BC58B", "#6EE259", "#52D170", "#D2A867", "#5C9CCD", "#DB6472", "#B9E8E0", "#CDE067", "#9C5615", "#536C4F",
                "#A74725", "#CBD88A", "#DF3066", "#E9D235", "#EE404C", "#7DB362", "#B1EDA3", "#71D2E1", "#A954DC", "#91DF6E",
                "#CB6429", "#D64ADC", "#DF3066", "#E90205", "#E04F4C", "#7D0360", "#01EDA3", "#716291", "#695DDC", "#919FFE",
            ]);


            var projection = d3.geoAlbersUsa()
                .scale(850)
                .translate([width / 2 - 60, height / 2 - 60]);
            var pathGenerator = d3.geoPath().projection(projection);

            var chart = d3.select("#map-chart")
                .selectAll("svg")
                .data([null])
                .join("svg")
                .attr("width", width)
                .attr("height", height)
                ;
            // d3.select("#map-chart .title")
            //     .html(opt.title);

            var svg = chart.selectAll(".main")
                .data([0])
                .join("g")
                .attr("class", "main")
                .attr("transform", `translate(${-30}, ${30})`);

            const counties = topojson.feature(map, map.objects.states);
            svg.selectAll('path')
                .data(counties.features)
                .join('path')
                .attr('class', d => {
                    if (dataMap[d.properties.name]) {
                        return 'counties m-' + getValue(dataMap[d.properties.name][currentYear]);
                    }
                    return 'counties'
                })
                .attr('title', (d) => d.properties.name)
                .style('fill', (d) => {
                    if (dataMap[d.properties.name]) {
                        return color(dataMap[d.properties.name][currentYear]);
                    }
                    return "#ccc";
                })
                .style("stroke", "#fff")
                .style("stroke-width", 1)
                .attr('d', (d) => pathGenerator(d))
                .on("mousemove", function (evt, d) {
                    var value = dataMap[d.properties.name][currentYear];
                    var strhtml = tooltipContent([
                        { name: "Home value", value: `${value}` },
                        { name: "Year", value: `${currentYear}` }
                    ], d.properties.name);

                    tooltip.html(strhtml)
                        .style("width", "auto")
                        .style("height", "auto")
                        .style("left", (evt.pageX - 80) + "px")
                        .style("top", (evt.pageY + 60) + "px")
                        .style("opacity", 0.8)
                        ;
                    d3.select(this)
                        .style("fill", hoverColor)
                        ;
                    d3.selectAll(`.lg-${getValue(value)}`)
                        .style("fill", hoverColor)
                        ;
                })
                .on("mouseout", function (evt, d) {
                    tooltip.style("width", 0)
                        .style("height", 0)
                        .style("opacity", 0.0);
                    d3.select(this)
                        .style('fill', (d) => {
                            if (dataMap[d.properties.name]) {
                                return color(dataMap[d.properties.name][currentYear]);
                            }
                            return "#ccc";
                        })
                        ;
                    d3.selectAll(`.legend-item`)
                        .style("fill", d => {
                            return color(sectionValues[d]);
                        })
                        ;
                })
                .on("click", function (evt, d) {
                    currentContinent = d.properties.name;
                })
                ;

            var legendSize = 20, legendData = [0, 1, 2, 3, 4, 5, 6],
                legendLeft = width - 250;
            var legendTop = (height - legendData.length * legendSize) / 2;

            var legend = svg.selectAll("#legend")
                .data([0])
                .join("g")
                .attr("id", "legend")
                .attr("transform", `translate(${legendLeft}, ${legendTop})`)
                ;
            legend.selectAll(".legend-item")
                .data(legendData)
                .enter()
                .append("rect")
                .attr("class", d => {
                    return "legend-item lg-" + sectionValues[d + 1];
                })
                .attr("width", legendSize)
                .attr("height", legendSize)
                .attr("x", 0)
                .attr("y", d => d * (legendSize + 8))
                .on("mousemove", function (evt, d) {
                    d3.selectAll(`.m-${sectionValues[d + 1]}`)
                        .style("fill", hoverColor)
                        ;
                    d3.select(this)
                        .style("fill", hoverColor)
                        ;
                })
                .on("mouseout", function (evt, e) {
                    tooltip.style("width", 0)
                        .style("height", 0)
                        .style("opacity", 0.0);
                    d3.selectAll(`.m-${sectionValues[e + 1]}`)
                        .style('fill', (d) => {
                            if (dataMap[d.properties.name]) {
                                return color(dataMap[d.properties.name][currentYear]);
                            }
                            return "#ccc";
                        })
                    d3.select(this)
                        .style("fill", d => {
                            return color(sectionValues[d]);
                        })
                        ;
                });

            legend.selectAll(".legend-item")
                .data(legendData)
                .style("fill", d => {
                    return color(sectionValues[d]);
                });

            legend.selectAll(".legend-txt")
                .data(legendData)
                .enter()
                .append("text")
                .attr("class", "legend-txt")
                .attr("dx", legendSize + 8)
                .attr("dy", d => d * (legendSize + 8) + 17);

            legend.selectAll(".legend-txt")
                .data(legendData)
                .text(d => `${sectionValues[d]} to ${sectionValues[d + 1]}`);
        }

        function drawMapChart() {
            MapChart({
                title: "æ ‡é¢˜",
                width: aWidth,
                height: aHeight,
                map: mapRoot,
                data: aData,
                max: max
            });
        }
        d3.json("counties-10m.json").then(function (root) {
            d3.csv("home_value_state_1.csv").then(function (data) {
                d3.selectAll(".page").style("display", "block");
                var columns = data.columns.slice(3);
                data.forEach(d => {
                    dataMap[d.Statename] = d;
                    columns.forEach(name => {
                        d[name] = +d[name];
                        max = Math.max(max, d[name]);
                    });
                });
                mapRoot = root;
                aData = data;

                $("#range-slider").ionRangeSlider({
                    skin: "sharp",
                    values: columns,
                    from: columns.length - 1,
                    grid: false,
                    grid_snap: false,
                    prefix: "",
                    onFinish: function (data) {
                        currentYear = columns[data.from];
                        drawMapChart();     // re-draw map using selected year
                    }
                });
                drawMapChart();     // draw map by default year
            });

        });
</script>

<!--chapter:end:06-interactive.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Conclusion


<!--chapter:end:07-conclusion.Rmd-->

